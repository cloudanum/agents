{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f39f1dc-fc65-4a32-a8a3-076bf7328700",
   "metadata": {},
   "source": [
    "# DocSense Lab — Document Intelligence, End-to-End\n",
    "\n",
    "**Goal:** Turn scanned documents (PDFs/images) into **structured, validated JSON** with **traceable provenance**.\n",
    "\n",
    "**Pipeline:**\n",
    "1. **Classify** → invoice/contract/unknown  \n",
    "2. **Preprocess** → deskew, denoise, binarize  \n",
    "3. **OCR** → extract text + per-word confidence + bounding boxes  \n",
    "4. **Layout** → detect table/line structure (lightweight morphology)  \n",
    "5. **Extract** → schema-driven fields (invoice #, date, total, vendor)  \n",
    "6. **Validate** → aggregate confidences, flag low-confidence results  \n",
    "7. **Route** → send high-confidence to systems, otherwise review\n",
    "\n",
    "**Why this lab?**  \n",
    "To demonstrate a reproducible, lightweight pattern for **explainable document AI** that runs locally in Jupyter with minimal dependencies.\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "### A) Environment\n",
    "- Install **Tesseract** (OCR engine)  \n",
    "  - macOS: `brew install tesseract`  \n",
    "  - Ubuntu: `sudo apt-get install tesseract-ocr`\n",
    "- (Optional for PDFs) Install **Poppler** (for `pdftoppm`)  \n",
    "  - macOS: `brew install poppler`  \n",
    "  - Ubuntu: `sudo apt-get install poppler-utils`\n",
    "\n",
    "### B) Python Packages\n",
    "```bash\n",
    "pip install opencv-python-headless pytesseract pdf2image Pillow numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3732e085-3f1b-414c-ac12-569125d63845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing missing packages: ['Pillow>=10.0.0']\n"
     ]
    }
   ],
   "source": [
    "# Environment setup for a regular Jupyter notebook (no Colab commands).\n",
    "# - Installs Python packages if missing.\n",
    "# - Warns if system dependencies (Tesseract, Poppler) are not present.\n",
    "\n",
    "import sys, subprocess, importlib, shutil\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\"] + pkgs)\n",
    "\n",
    "required = {\n",
    "    \"opencv-python-headless\": \"opencv-python-headless>=4.8.0\",  # cv2\n",
    "    \"pytesseract\": \"pytesseract>=0.3.10\",\n",
    "    \"pdf2image\": \"pdf2image>=1.17.0\",   # optional if you won’t handle PDFs\n",
    "    \"Pillow\": \"Pillow>=10.0.0\",\n",
    "    \"numpy\": \"numpy>=1.23.0\",\n",
    "}\n",
    "\n",
    "to_install = []\n",
    "# cv2 module name is \"cv2\" even if pkg is opencv-python-headless\n",
    "try:\n",
    "    import cv2  # noqa: F401\n",
    "except Exception:\n",
    "    to_install.append(required[\"opencv-python-headless\"])\n",
    "\n",
    "for mod, spec in required.items():\n",
    "    if mod == \"opencv-python-headless\":\n",
    "        continue  # already handled via cv2 import\n",
    "    try:\n",
    "        importlib.import_module(mod)\n",
    "    except Exception:\n",
    "        to_install.append(spec)\n",
    "\n",
    "if to_install:\n",
    "    print(\"Installing missing packages:\", to_install)\n",
    "    pip_install(to_install)\n",
    "\n",
    "# System dependency checks (helpful messages if missing)\n",
    "if not shutil.which(\"tesseract\"):\n",
    "    print(\"⚠ Tesseract not found. Install it first:\")\n",
    "    print(\"  • macOS:  brew install tesseract\")\n",
    "    print(\"  • Ubuntu: sudo apt-get install tesseract-ocr\")\n",
    "if not shutil.which(\"pdftoppm\"):\n",
    "    print(\"⚠ Poppler (pdftoppm) not found (needed only for PDF input):\")\n",
    "    print(\"  • macOS:  brew install poppler\")\n",
    "    print(\"  • Ubuntu: sudo apt-get install poppler-utils\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f70e51-ff8b-46af-83a5-d847324133f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports required for the pipeline\n",
    "import os, re, json, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "\n",
    "# pdf2image is optional—if Poppler isn't installed, we gracefully skip PDF input\n",
    "try:\n",
    "    from pdf2image import convert_from_path\n",
    "except Exception:\n",
    "    convert_from_path = None\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Ensure pytesseract uses the system tesseract binary, if available\n",
    "tesseract_bin = shutil.which(\"tesseract\")\n",
    "if tesseract_bin:\n",
    "    pytesseract.pytesseract.tesseract_cmd = tesseract_bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56511b54-ca9b-4092-8187-d5c46c50898c",
   "metadata": {},
   "source": [
    "\n",
    "## FAQ\n",
    "\n",
    "**Q: Do I need Poppler installed?**  \n",
    "A: Only if you process PDFs. For images (PNG/JPG), you don’t.\n",
    "\n",
    "**Q: Why is the table detector “simple”?**  \n",
    "A: To keep the lab explainable and dependency-light. You can swap in a stronger table model when needed.\n",
    "\n",
    "**Q: Where do confidence numbers come from?**  \n",
    "A: Tesseract’s per-token confidences, aggregated at the field level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b77ab411-2ddd-4537-8855-4e3bcbdc22a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data/sample_invoice.png\n",
      "Document type: invoice\n",
      "OCR average confidence: 0.88\n",
      "Contains table: True\n",
      "\n",
      "Extracted Data (excluding per-field confidences):\n",
      "{\n",
      "  \"invoice_number\": null,\n",
      "  \"invoice_date\": null,\n",
      "  \"total_amount\": \"13\",\n",
      "  \"vendor_name\": \"Wayne Enterprises\",\n",
      "  \"average_confidence\": 0.73,\n",
      "  \"needs_review\": true,\n",
      "  \"review_reason\": \"Low confidence in: total_amount\"\n",
      "}\n",
      "\n",
      "Confidence Scores:\n",
      "{\n",
      "  \"total_amount\": 0.5,\n",
      "  \"vendor_name\": 0.96\n",
      "}\n",
      "\n",
      "⚠ ROUTING TO HUMAN REVIEW: Low confidence in: total_amount\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Complete, runnable version of the user's snippet for a regular Jupyter notebook.\n",
    "\n",
    "Key additions:\n",
    "- Synthetic invoice image generator so the notebook runs without external files.\n",
    "- Robust handling when pdf2image/Poppler is unavailable.\n",
    "- Auto-configuration of Tesseract path.\n",
    "- Clear, commented main execution that demonstrates the full pipeline.\n",
    "\"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Classification\n",
    "# -----------------------------\n",
    "def classify_document(file_path: str) -> str:\n",
    "    \"\"\"Determine document type based on content patterns.\"\"\"\n",
    "    image = None\n",
    "    suffix = Path(file_path).suffix.lower()\n",
    "\n",
    "    # Convert first page of PDF to image if possible\n",
    "    if suffix == \".pdf\":\n",
    "        if convert_from_path is None:\n",
    "            raise RuntimeError(\"PDF input requested but pdf2image/Poppler not available.\")\n",
    "        images = convert_from_path(file_path, first_page=1, last_page=1)\n",
    "        image = np.array(images[0])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    else:\n",
    "        image = cv2.imread(file_path)\n",
    "\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Could not read: {file_path}\")\n",
    "\n",
    "    # Quick OCR to detect document type\n",
    "    text = pytesseract.image_to_string(image).lower()\n",
    "\n",
    "    if any(x in text for x in (\"invoice\", \"bill to\", \"total amount\", \"amount due\")):\n",
    "        return \"invoice\"\n",
    "    elif any(x in text for x in (\"contract\", \"agreement\")):\n",
    "        return \"contract\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Preprocessing + OCR\n",
    "# -----------------------------\n",
    "def preprocess_image(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Enhance image quality before OCR (grayscale, deskew, denoise, binarize).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Deskew\n",
    "    coords = np.column_stack(np.where(gray > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    angle = -(90 + angle) if angle < -45 else -angle\n",
    "    (h, w) = gray.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)\n",
    "    rotated = cv2.warpAffine(gray, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "    # Denoise + binarize\n",
    "    denoised = cv2.fastNlMeansDenoising(rotated)\n",
    "    _, enhanced = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return enhanced\n",
    "\n",
    "\n",
    "def perform_ocr_with_confidence(image: np.ndarray) -> dict:\n",
    "    \"\"\"Extract text + per-word confidence and bounding boxes.\"\"\"\n",
    "    ocr_data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n",
    "\n",
    "    results = {\n",
    "        \"text\": pytesseract.image_to_string(image),\n",
    "        \"words\": [],\n",
    "        \"average_confidence\": 0.0,\n",
    "    }\n",
    "\n",
    "    confidences = []\n",
    "    n = len(ocr_data.get(\"text\", []))\n",
    "    for i in range(n):\n",
    "        try:\n",
    "            conf = float(ocr_data[\"conf\"][i])\n",
    "        except Exception:\n",
    "            conf = -1.0\n",
    "        token = (ocr_data[\"text\"][i] or \"\").strip()\n",
    "\n",
    "        if token and conf > 0:\n",
    "            results[\"words\"].append(\n",
    "                {\n",
    "                    \"text\": token,\n",
    "                    \"confidence\": conf / 100.0,\n",
    "                    \"bbox\": (\n",
    "                        int(ocr_data[\"left\"][i]),\n",
    "                        int(ocr_data[\"top\"][i]),\n",
    "                        int(ocr_data[\"width\"][i]),\n",
    "                        int(ocr_data[\"height\"][i]),\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "            confidences.append(conf)\n",
    "\n",
    "    if confidences:\n",
    "        results[\"average_confidence\"] = (sum(confidences) / len(confidences)) / 100.0\n",
    "    return results\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Layout parsing (simple)\n",
    "# -----------------------------\n",
    "def detect_layout_regions(image: np.ndarray) -> dict:\n",
    "    \"\"\"Identify simple table structures using morphological ops.\"\"\"\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))\n",
    "\n",
    "    horizontal_lines = cv2.morphologyEx(image, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "    vertical_lines = cv2.morphologyEx(image, cv2.MORPH_OPEN, vertical_kernel)\n",
    "\n",
    "    table_mask = cv2.addWeighted(horizontal_lines, 0.5, vertical_lines, 0.5, 0.0)\n",
    "    return {\"has_table\": int(np.sum(table_mask)) > 1000, \"table_regions\": []}\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Field extraction helpers\n",
    "# -----------------------------\n",
    "def find_confidence_for_text(target_text: str, ocr_results: dict) -> float:\n",
    "    \"\"\"Estimate confidence for a span by averaging token confidences.\"\"\"\n",
    "    confidences = []\n",
    "    target_words = target_text.lower().split()\n",
    "    for word_data in ocr_results[\"words\"]:\n",
    "        if word_data[\"text\"].lower() in target_words:\n",
    "            confidences.append(word_data[\"confidence\"])\n",
    "    return float(sum(confidences) / len(confidences)) if confidences else 0.5\n",
    "\n",
    "\n",
    "def extract_invoice_fields(text: str, ocr_results: dict) -> dict:\n",
    "    \"\"\"Schema-driven extraction of common invoice fields.\"\"\"\n",
    "    out = {\n",
    "        \"invoice_number\": None,\n",
    "        \"invoice_date\": None,\n",
    "        \"total_amount\": None,\n",
    "        \"vendor_name\": None,\n",
    "        \"confidence_scores\": {},\n",
    "    }\n",
    "\n",
    "    # Invoice number\n",
    "    m = re.search(r\"invoice\\s*#?\\s*:?\\s*([A-Z0-9-]+)\", text, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        out[\"invoice_number\"] = m.group(1)\n",
    "        out[\"confidence_scores\"][\"invoice_number\"] = find_confidence_for_text(m.group(1), ocr_results)\n",
    "\n",
    "    # Date (DD/MM/YYYY, MM-DD-YY, etc.)\n",
    "    m = re.search(r\"(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4})\", text)\n",
    "    if m:\n",
    "        out[\"invoice_date\"] = m.group(1)\n",
    "        out[\"confidence_scores\"][\"invoice_date\"] = find_confidence_for_text(m.group(1), ocr_results)\n",
    "\n",
    "    # Total\n",
    "    m = re.search(r\"total[:\\s]+\\$?\\s*([\\d,]+\\.?\\d*)\", text, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        amt = m.group(1).replace(\",\", \"\")\n",
    "        out[\"total_amount\"] = amt\n",
    "        out[\"confidence_scores\"][\"total_amount\"] = find_confidence_for_text(m.group(1), ocr_results)\n",
    "\n",
    "    # Vendor (first non-empty line)\n",
    "    first_line = next((ln.strip() for ln in text.splitlines() if ln.strip()), \"\")\n",
    "    if first_line:\n",
    "        out[\"vendor_name\"] = first_line\n",
    "        out[\"confidence_scores\"][\"vendor_name\"] = find_confidence_for_text(first_line, ocr_results)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Validation & routing\n",
    "# -----------------------------\n",
    "def validate_and_route(extracted: dict, confidence_threshold: float = 0.85) -> dict:\n",
    "    if not extracted.get(\"confidence_scores\"):\n",
    "        extracted[\"needs_review\"] = True\n",
    "        extracted[\"review_reason\"] = \"No confidence scores available\"\n",
    "        extracted[\"average_confidence\"] = 0.0\n",
    "        return extracted\n",
    "\n",
    "    scores = list(extracted[\"confidence_scores\"].values())\n",
    "    min_conf = min(scores)\n",
    "    avg_conf = sum(scores) / len(scores)\n",
    "\n",
    "    extracted[\"average_confidence\"] = avg_conf\n",
    "    extracted[\"needs_review\"] = min_conf < confidence_threshold\n",
    "    if extracted[\"needs_review\"]:\n",
    "        low_fields = [k for k, v in extracted[\"confidence_scores\"].items() if v < confidence_threshold]\n",
    "        extracted[\"review_reason\"] = f\"Low confidence in: {', '.join(low_fields)}\"\n",
    "    return extracted\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Full pipeline\n",
    "# -----------------------------\n",
    "def process_document(file_path: str) -> dict:\n",
    "    print(f\"Processing: {file_path}\")\n",
    "\n",
    "    # Stage 1: Classification\n",
    "    doc_type = classify_document(file_path)\n",
    "    print(f\"Document type: {doc_type}\")\n",
    "\n",
    "    # Load image (1st page for PDF)\n",
    "    suffix = Path(file_path).suffix.lower()\n",
    "    if suffix == \".pdf\":\n",
    "        if convert_from_path is None:\n",
    "            raise RuntimeError(\"pdf2image/Poppler not available; cannot read PDFs.\")\n",
    "        images = convert_from_path(file_path, first_page=1, last_page=1)\n",
    "        image = np.array(images[0])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    else:\n",
    "        image = cv2.imread(file_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Could not read: {file_path}\")\n",
    "\n",
    "    # Stage 2: Preprocess + OCR\n",
    "    preprocessed = preprocess_image(image)\n",
    "    ocr_results = perform_ocr_with_confidence(preprocessed)\n",
    "    print(f\"OCR average confidence: {ocr_results['average_confidence']:.2f}\")\n",
    "\n",
    "    # Stage 3: Layout\n",
    "    layout = detect_layout_regions(preprocessed)\n",
    "    print(f\"Contains table: {layout['has_table']}\")\n",
    "\n",
    "    # Stage 4: Extraction\n",
    "    extracted = extract_invoice_fields(ocr_results[\"text\"], ocr_results)\n",
    "\n",
    "    # Stage 5: Validation\n",
    "    final_result = validate_and_route(extracted)\n",
    "    return final_result\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Utility: Generate a synthetic invoice image so this notebook runs anywhere\n",
    "# -----------------------------\n",
    "def make_synthetic_invoice_image(path: str, seed: int = 42) -> str:\n",
    "    img = Image.new(\"RGB\", (1654, 2339), color=\"white\")  # ~A4 at 150 dpi\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Try to use a clean sans-serif font; fall back to default\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 36)\n",
    "        font_bold = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 56)\n",
    "    except Exception:\n",
    "        font = ImageFont.load_default()\n",
    "        font_bold = font\n",
    "\n",
    "    # Header / vendor\n",
    "    draw.text((80, 80), \"ACME Corporation\", fill=(0, 0, 0), font=font_bold)\n",
    "    draw.text((80, 160), \"123 Industrial Road\", fill=(0, 0, 0), font=font)\n",
    "    draw.text((80, 200), \"Metropolis, NY 10001\", fill=(0, 0, 0), font=font)\n",
    "\n",
    "    # Invoice title & meta\n",
    "    draw.text((1100, 80), \"INVOICE\", fill=(0, 0, 0), font=font_bold)\n",
    "    draw.text((1100, 150), \"Invoice #: INV-2024-001\", fill=(0, 0, 0), font=font)\n",
    "    draw.text((1100, 190), \"Date: 12/31/2024\", fill=(0, 0, 0), font=font)\n",
    "\n",
    "    # Bill To\n",
    "    draw.text((80, 300), \"Bill To:\", fill=(0, 0, 0), font=font_bold)\n",
    "    draw.text((80, 350), \"Wayne Enterprises\", fill=(0, 0, 0), font=font)\n",
    "    draw.text((80, 390), \"1007 Mountain Drive\", fill=(0, 0, 0), font=font)\n",
    "    draw.text((80, 430), \"Gotham, NJ 07001\", fill=(0, 0, 0), font=font)\n",
    "\n",
    "    # A simple table header line\n",
    "    draw.line([(80, 520), (1570, 520)], fill=(0, 0, 0), width=3)\n",
    "    draw.text((80, 540), \"Description\", fill=(0, 0, 0), font=font_bold)\n",
    "    draw.text((1100, 540), \"Qty\", fill=(0, 0, 0), font=font_bold)\n",
    "    draw.text((1250, 540), \"Unit Price\", fill=(0, 0, 0), font=font_bold)\n",
    "    draw.text((1450, 540), \"Amount\", fill=(0, 0, 0), font=font_bold)\n",
    "    draw.line([(80, 590), (1570, 590)], fill=(0, 0, 0), width=3)\n",
    "\n",
    "    # A couple of rows\n",
    "    y = 620\n",
    "    rows = [\n",
    "        (\"Widget A\", \"2\", \"$199.50\", \"$399.00\"),\n",
    "        (\"Gizmo B\", \"1\", \"$799.00\", \"$799.00\"),\n",
    "        (\"Service Plan\", \"1\", \"$150.00\", \"$150.00\"),\n",
    "    ]\n",
    "    for desc, qty, unit, amt in rows:\n",
    "        draw.text((80, y), desc, fill=(0, 0, 0), font=font)\n",
    "        draw.text((1100, y), qty, fill=(0, 0, 0), font=font)\n",
    "        draw.text((1250, y), unit, fill=(0, 0, 0), font=font)\n",
    "        draw.text((1450, y), amt, fill=(0, 0, 0), font=font)\n",
    "        y += 60\n",
    "\n",
    "    draw.line([(80, y + 10), (1570, y + 10)], fill=(0, 0, 0), width=3)\n",
    "    draw.text((1200, y + 60), \"TOTAL      $1,348.00\", fill=(0, 0, 0), font=font_bold)\n",
    "\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    img.save(path)\n",
    "    return path\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main execution\n",
    "# -----------------------------\n",
    "def run_demo():\n",
    "    # 1) Create a synthetic invoice image so the pipeline always has input\n",
    "    sample_image_path = \"data/sample_invoice.png\"\n",
    "    make_synthetic_invoice_image(sample_image_path)\n",
    "\n",
    "    # 2) Process the synthetic invoice\n",
    "    result = process_document(sample_image_path)\n",
    "\n",
    "    # 3) Display results\n",
    "    print(\"\\nExtracted Data (excluding per-field confidences):\")\n",
    "    print(json.dumps({k: v for k, v in result.items() if k not in (\"confidence_scores\",)}, indent=2))\n",
    "\n",
    "    print(\"\\nConfidence Scores:\")\n",
    "    print(json.dumps(result.get(\"confidence_scores\", {}), indent=2))\n",
    "\n",
    "    if result.get(\"needs_review\"):\n",
    "        print(f\"\\n⚠ ROUTING TO HUMAN REVIEW: {result.get('review_reason', 'Unknown reason')}\")\n",
    "    else:\n",
    "        print(\"\\n✓ HIGH CONFIDENCE: Sending to ERP system\")\n",
    "\n",
    "# Execute demo\n",
    "run_demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2426d99-a16f-4c15-9bbf-9af72673c903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
